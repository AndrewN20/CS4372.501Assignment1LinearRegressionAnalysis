# -*- coding: utf-8 -*-
"""(LATEST) CS4372Project1NewNew

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O7Y59YPi5H-ObLZMrs3BBXR2F1JdSasV

# Importing and Setting Up Dataset
"""

pip install ucimlrepo

from ucimlrepo import fetch_ucirepo
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import SGDRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score
import statsmodels.api as sm
label_encoder = LabelEncoder()
scaler = StandardScaler()

from ucimlrepo import fetch_ucirepo

# https://archive.ics.uci.edu/dataset/294/combined+cycle+power+plant
# fetch dataset
combined_cycle_power_plant = fetch_ucirepo(id=294)

# data (as pandas dataframes)
X = combined_cycle_power_plant.data.features
y = combined_cycle_power_plant.data.targets

# metadata
print(combined_cycle_power_plant.metadata)

# variable information
print(combined_cycle_power_plant.variables)

import pandas as pd
import numpy as np
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns

#Renaming the features to their full names listed from Dataset website
X.columns = ["Temperature", "Exhaust Vacuum", "Ambient Pressure", "Relative Humidity"]
print(X)

#Renaming the target to the full name listed from Dataset website
y.columns = ["Energy Output"]
print(y)

#Double check if there are still null values
print(X.isnull().sum())

#Double check if there are still null values
print(y.isnull().sum())

"""# Create Graphs to Find Correlations"""

#Created Boxplot to see if there is any outliers
sns.boxplot(X, orient= 'h')
plt.show()

#Created pairplot to see correlation between features
sns.pairplot(X)
plt.show()

#Created histogram to see distribution of features
X.hist(figsize=(15,12))
plt.show()

#Created correlation heatmap to better visualize the pairplots
corr = X.corr(numeric_only=True)
plt.figure(figsize=(10,8))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", center=0)
plt.title("Correlation Heatmap (Energy Production Dataset)")
plt.show()

#Exhaust Vacuum vs Engergy Output
plt.figure(figsize=(6,4))
sns.scatterplot(x=X["Exhaust Vacuum"], y=y["Energy Output"], alpha=0.5)
plt.xlabel("Exhaust Vacuum")
plt.ylabel("Energy Output")
plt.title("Exhaust Vacuum vs Energy Output")
plt.show()

#Temperature vs Energy Output
plt.figure(figsize=(6,4))
sns.scatterplot(x=X["Temperature"], y=y["Energy Output"], alpha=0.5)
plt.xlabel("Temperature")
plt.ylabel("Energy Output")
plt.title("Temperature vs Energy Output")
plt.show()

#Ambient Pressure vs Engery Output
plt.figure(figsize=(6,4))
sns.scatterplot(x=X["Ambient Pressure"], y=y["Energy Output"], alpha=0.5)
plt.xlabel("Ambient Pressure")
plt.ylabel("Energy Output")
plt.title("Ambient Pressure vs Energy Output")
plt.show()

#Relative Humidity vs Energy Output
plt.figure(figsize=(6,4))
sns.scatterplot(x=X["Relative Humidity"], y=y["Energy Output"], alpha=0.5)
plt.xlabel("Relative Humidity")
plt.ylabel("Energy Output")
plt.title("Relative Humidity vs Energy Output")
plt.show()

#Drop Relative Humidity and Ambient Pressure from X
X = X.drop(["Ambient Pressure", "Relative Humidity"], axis=1)
print(X)

"""# Preprocessing/Spliting Data into Training and Testing"""

#Transform X into X_scaled
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled)
print(X_scaled)

#Standerdize y to be an array and one dimensional
y = y.to_numpy()
y = y.ravel()
print(y)

#Split data into testing and training data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=5)

"""# SDG Regressor"""

#Hyper Parameters and using the Regressor Model
alphaVar = 1
eta0Var = 1
maxIterVar = 100000000
tolVar = 1e-05
learningRateVar = "invscaling"
penaltyVar = "l1"
SGDmodel = SGDRegressor(alpha = 1, eta0=eta0Var, max_iter = maxIterVar, tol = tolVar, learning_rate = learningRateVar, penalty = penaltyVar)
SGDmodel.fit(X_train, y_train)

#Use for seeing how well target prediction matches target actual
y_predSGD = SGDmodel.predict(X_test)

SGDmodel.coef_

SGDmodel.intercept_

SGDmodel.score(X_test, y_test)

mse = mean_squared_error(y_test, y_predSGD)
mae = mean_absolute_error(y_test, y_predSGD)
ev = explained_variance_score(y_test, y_predSGD)
r2 = r2_score(y_test, y_predSGD)
mse, mae, ev, r2

"""# OLS Model"""

#More standarization method, as without it, the evaluation will look skewed
X_train_const = sm.add_constant(X_train)
X_test_const = sm.add_constant(X_test)
print(X_train_const)
print(X_test_const)

model = sm.OLS(y_train, X_train_const)
results = model.fit()
print(results.summary())

#Use for seeing how well target prediction matches target actual
y_predOLS = results.predict(X_test_const)

mse = mean_squared_error(y_test, y_predOLS)
mae = mean_absolute_error(y_test, y_predOLS)
ev = explained_variance_score(y_test, y_predOLS)
r2 = r2_score(y_test, y_predOLS)
mse, mae, ev, r2

sm.tools.eval_measures.rmse(y_test, y_predOLS)